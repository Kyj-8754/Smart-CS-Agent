"""
BíŒŒíŠ¸: í†µí•© ì§€ì‹ ì„œë¹„ìŠ¤ (All-in-One)
- ëŒ€í™” ë§¥ë½ ê´€ë¦¬ (ConversationManager í†µí•©)
- FAQ ê²€ìƒ‰ (KnowledgeService)
- ê·œì¹™ ê¸°ë°˜ íŒë‹¨
"""

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Tuple
from pathlib import Path
from datetime import datetime
import logging
import os
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ==================== ëŒ€í™” ë§¥ë½ ê´€ë¦¬ì ====================

class ConversationManager:
    """
    ëŒ€í™” ë§¥ë½ ê´€ë¦¬
    
    ê¸°ëŠ¥:
    1. ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ì €ì¥
    2. ì§€ì‹œ ëŒ€ëª…ì‚¬ í•´ê²°
    3. ì‹œë„í•œ í•´ê²°ì±… ì¶”ì 
    """
    
    def __init__(self):
        self.sessions = {}
    
    def add_turn(self, 
                 session_id: str, 
                 user_query: str, 
                 bot_response: str,
                 suggested_action: str = None,
                 faq_id: str = None):
        """ëŒ€í™” í„´ ì¶”ê°€"""
        if session_id not in self.sessions:
            self.sessions[session_id] = {
                'history': [],
                'current_issue': None,
                'tried_solutions': [],
                'last_suggestion': None,
                'created_at': datetime.now()
            }
        
        self.sessions[session_id]['history'].append({
            'timestamp': datetime.now(),
            'user_query': user_query,
            'bot_response': bot_response,
            'suggested_action': suggested_action,
            'faq_id': faq_id
        })
        
        if suggested_action:
            self.sessions[session_id]['last_suggestion'] = suggested_action
            self.sessions[session_id]['tried_solutions'].append(suggested_action)
        
        if not self.sessions[session_id]['current_issue']:
            self.sessions[session_id]['current_issue'] = self._extract_issue(user_query)
    
    def _extract_issue(self, query: str) -> str:
        """í˜„ì¬ ë¬¸ì œ ì¶”ì¶œ"""
        issues = {
            'ì¸í„°ë„·': 'internet_issue',
            'ì™€ì´íŒŒì´': 'wifi_issue',
            'ì•±': 'app_issue',
            'ëŠë¦¼': 'slow_issue',
            'ì²­êµ¬': 'billing_issue',
            'ì£¼ë¬¸': 'order_issue',
            'ë¡œê·¸ì¸': 'login_issue'
        }
        
        for keyword, issue in issues.items():
            if keyword in query:
                return issue
        
        return 'general_issue'
    
    def resolve_references(self, session_id: str, query: str) -> str:
        """ì§€ì‹œ ëŒ€ëª…ì‚¬ í•´ê²°"""
        if session_id not in self.sessions:
            return query
        
        context = self.sessions[session_id]
        
        if not context['last_suggestion']:
            return query
        
        references = {
            'ê·¸ê±°': context['last_suggestion'],
            'ê·¸ê²ƒ': context['last_suggestion'],
            'ì´ê±°': context['last_suggestion'],
            'ì´ê²ƒ': context['last_suggestion'],
            'ì €ê±°': context['last_suggestion'],
            'ì €ê²ƒ': context['last_suggestion'],
            'ê·¸ë ‡ê²Œ': context['last_suggestion'],
            'ì´ë ‡ê²Œ': context['last_suggestion']
        }
        
        resolved = query
        for ref, actual in references.items():
            if ref in resolved:
                resolved = resolved.replace(ref, actual)
                
                if actual not in context['tried_solutions']:
                    context['tried_solutions'].append(actual)
        
        if resolved != query:
            logger.info(f"[ë§¥ë½ í•´ê²°] '{query}' â†’ '{resolved}'")
        
        return resolved
    
    def get_context_summary(self, session_id: str) -> Dict:
        """í˜„ì¬ ë§¥ë½ ìš”ì•½"""
        if session_id not in self.sessions:
            return {'has_context': False}
        
        context = self.sessions[session_id]
        
        return {
            'has_context': True,
            'turn_count': len(context['history']),
            'current_issue': context['current_issue'],
            'tried_solutions': context['tried_solutions'],
            'last_suggestion': context['last_suggestion']
        }
    
    def add_context_to_prompt(self, session_id: str, query: str) -> str:
        """AI í”„ë¡¬í”„íŠ¸ì— ë§¥ë½ ì¶”ê°€"""
        if session_id not in self.sessions:
            return query
        
        context = self.sessions[session_id]
        
        if not context['tried_solutions']:
            return query
        
        context_text = f"[ì´ì „ ëŒ€í™” ë§¥ë½]\n"
        context_text += f"- í˜„ì¬ ë¬¸ì œ: {context['current_issue']}\n"
        context_text += f"- ì´ë¯¸ ì‹œë„í•œ ë°©ë²•: {', '.join(context['tried_solutions'])}\n\n"
        context_text += f"[í˜„ì¬ ì§ˆë¬¸]\n{query}"
        
        return context_text
    
    def clear_session(self, session_id: str):
        """ì„¸ì…˜ ì‚­ì œ"""
        if session_id in self.sessions:
            del self.sessions[session_id]
    
    def cleanup_old_sessions(self, hours: int = 24):
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬"""
        now = datetime.now()
        to_delete = []
        
        for session_id, context in self.sessions.items():
            age = (now - context['created_at']).total_seconds() / 3600
            if age > hours:
                to_delete.append(session_id)
        
        for session_id in to_delete:
            del self.sessions[session_id]
        
        return len(to_delete)


# ==================== ì§€ì‹ ì„œë¹„ìŠ¤ ====================

class KnowledgeService:
    """
    í†µí•© ì§€ì‹ ì„œë¹„ìŠ¤
    
    ê¸°ëŠ¥:
    - FAQ ê²€ìƒ‰ (FAISS)
    - ê·œì¹™ ê¸°ë°˜ ì• ë§¤ëª¨í˜¸ íŒë‹¨
    - ëŒ€í™” ë§¥ë½ ìœ ì§€
    - AI fallback (ì„ íƒ)
    """
    
    def __init__(self, 
                 csv_path: str = "data/faq_database.csv",
                 model_name: str = "jhgan/ko-sroberta-multitask",
                 use_ai_fallback: bool = False,
                 enable_conversation: bool = True):
        
        logger.info("=" * 60)
        logger.info("BíŒŒíŠ¸: í†µí•© ì§€ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        logger.info("=" * 60)
        
        self.csv_path = csv_path
        self.use_ai_fallback = use_ai_fallback
        self.enable_conversation = enable_conversation
        
        # ëŒ€í™” ë§¥ë½ ê´€ë¦¬ì
        if enable_conversation:
            self.conversation = ConversationManager()
            logger.info("  âœ… ëŒ€í™” ë§¥ë½ ê´€ë¦¬ í™œì„±í™”")
        else:
            self.conversation = None
        
        # ì„ë² ë”© ëª¨ë¸
        logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {model_name}")
        try:
            self.model = SentenceTransformer(model_name)
            self.dimension = self.model.get_sentence_embedding_dimension()
            logger.info(f"  âœ… ì„ë² ë”© ì°¨ì›: {self.dimension}")
        except Exception as e:
            logger.error(f"  âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        # CSV ë¡œë“œ
        self.faq_df = self._load_csv()
        
        # FAISS ì¸ë±ìŠ¤
        self.index = None
        if not self.faq_df.empty:
            self.index = self._build_index()
        
        # AI API (ì„ íƒ)
        self.ai_client = None
        if use_ai_fallback:
            self._setup_ai_api()
        
        logger.info("âœ… í†µí•© ì§€ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ\n")
    
    def _setup_ai_api(self):
        """AI API ì„¤ì •"""
        try:
            key = os.getenv("OPENAI_API_KEY")
            if not key:
                logger.warning("âš ï¸  OpenAI API í‚¤ ì—†ìŒ")
                self.use_ai_fallback = False
                return
            
            from openai import OpenAI
            self.ai_client = OpenAI(api_key=key)
            logger.info("  âœ… AI API ì„¤ì • ì™„ë£Œ")
            
        except ImportError:
            logger.warning("âš ï¸  openai íŒ¨í‚¤ì§€ ì—†ìŒ")
            self.use_ai_fallback = False
        except Exception as e:
            logger.warning(f"âš ï¸  AI API ì„¤ì • ì‹¤íŒ¨: {e}")
            self.use_ai_fallback = False
    
    def _load_csv(self) -> pd.DataFrame:
        """CSV ë¡œë“œ"""
        csv_file = Path(self.csv_path)
        
        if not csv_file.exists():
            logger.error(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {self.csv_path}")
            raise FileNotFoundError(f"FAQ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.csv_path}")
        
        try:
            df = pd.read_csv(csv_file, encoding='utf-8')
            logger.info(f"  âœ… CSV ë¡œë“œ: {len(df)}ê°œ FAQ")
            
            required = ['id', 'category', 'question', 'answer']
            missing = [col for col in required if col not in df.columns]
            if missing:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
            
            return df
            
        except Exception as e:
            logger.error(f"  âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _build_index(self):
        """FAISS ì¸ë±ìŠ¤ ìƒì„±"""
        logger.info("FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        
        try:
            texts = []
            for idx, row in self.faq_df.iterrows():
                text = row['question']
                if 'keywords' in self.faq_df.columns and pd.notna(row['keywords']):
                    text += " " + row['keywords'].replace(',', ' ')
                texts.append(text)
            
            embeddings = self.model.encode(
                texts,
                convert_to_numpy=True,
                show_progress_bar=False
            )
            
            faiss.normalize_L2(embeddings)
            
            index = faiss.IndexFlatIP(self.dimension)
            index.add(embeddings)
            
            logger.info(f"  âœ… FAISS ì¸ë±ìŠ¤: {index.ntotal}ê°œ ë²¡í„°")
            return index
            
        except Exception as e:
            logger.error(f"  âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _is_ambiguous(self, query: str, similarity_score: float, category: str) -> Tuple[bool, str]:
        """ê·œì¹™ ê¸°ë°˜ ì• ë§¤ëª¨í˜¸ íŒë‹¨"""
        if similarity_score < 0.6:
            
            ambiguous_patterns = {
                'ì£¼ì–´ ì—†ìŒ': ['ëŠë ¤ìš”', 'ì•ˆ ë¼ìš”', 'ì•ˆ ë©ë‹ˆë‹¤', 'ì´ìƒí•´ìš”', 'ë¬¸ì œ', 'ì˜¤ë¥˜ì˜ˆìš”'],
                'ì§€ì‹œì–´': ['ê·¸ê±°', 'ì´ê±°', 'ì €ê±°', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ'],
                'ë¶ˆì™„ì „': ['ì™œ', 'ë­', 'ì–´ë–»ê²Œ', 'ì–¸ì œ']
            }
            
            for pattern_type, patterns in ambiguous_patterns.items():
                if any(pattern in query for pattern in patterns):
                    
                    specific_nouns = {
                        'tech_support': ['ì¸í„°ë„·', 'ì™€ì´íŒŒì´', 'ì•±', 'ê¸°ê¸°', 'í™”ë©´', 'ì†Œë¦¬'],
                        'billing_support': ['ì²­êµ¬ì„œ', 'ìš”ê¸ˆ', 'ê²°ì œ', 'í™˜ë¶ˆ', 'ì˜ìˆ˜ì¦'],
                        'order_management': ['ì£¼ë¬¸', 'ë°°ì†¡', 'êµí™˜', 'ë°˜í’ˆ', 'ì·¨ì†Œ'],
                        'account_management': ['ë¹„ë°€ë²ˆí˜¸', 'ë¡œê·¸ì¸', 'ê³„ì •', 'íšŒì›', 'ê°€ì…']
                    }
                    
                    category_nouns = specific_nouns.get(category, [])
                    has_specific = any(noun in query for noun in category_nouns)
                    
                    if not has_specific:
                        return True, f"{pattern_type}"
        
        return False, ""
    
    def _generate_clarification_question(self, category: str, faq_results: List[Dict]) -> str:
        """ëª…í™•í™” ì§ˆë¬¸ ìƒì„±"""
        templates = {
            'tech_support': {
                'title': 'ê¸°ìˆ  ì§€ì›',
                'options': [
                    'ğŸŒ ì¸í„°ë„·/ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ',
                    'ğŸ“± ì•±/í”„ë¡œê·¸ë¨ ë¬¸ì œ',
                    'ğŸ’» ê¸°ê¸° í•˜ë“œì›¨ì–´ ë¬¸ì œ',
                    'ğŸ”Š ì†Œë¦¬/í™”ë©´ ë¬¸ì œ'
                ]
            },
            'billing_support': {
                'title': 'ì²­êµ¬ ì§€ì›',
                'options': [
                    'ğŸ“‹ ì²­êµ¬ì„œ í™•ì¸',
                    'ğŸ’³ ê²°ì œ ë¬¸ì œ',
                    'ğŸ’° í™˜ë¶ˆ ìš”ì²­',
                    'ğŸ”„ ìë™ê²°ì œ ê´€ë¦¬'
                ]
            },
            'order_management': {
                'title': 'ì£¼ë¬¸ ê´€ë¦¬',
                'options': [
                    'âŒ ì£¼ë¬¸ ì·¨ì†Œ',
                    'ğŸ“¦ ë°°ì†¡ ë¬¸ì˜',
                    'ğŸ”„ êµí™˜/ë°˜í’ˆ',
                    'ğŸ“ ë°°ì†¡ì§€ ë³€ê²½'
                ]
            },
            'account_management': {
                'title': 'ê³„ì • ê´€ë¦¬',
                'options': [
                    'ğŸ” ë¹„ë°€ë²ˆí˜¸ ë¬¸ì œ',
                    'ğŸšª ë¡œê·¸ì¸ ë¬¸ì œ',
                    'âœï¸  ì •ë³´ ìˆ˜ì •',
                    'ğŸš« íšŒì› íƒˆí‡´'
                ]
            }
        }
        
        template = templates.get(category, {
            'title': 'ë¬¸ì˜',
            'options': ['ê¸°íƒ€ ë¬¸ì˜']
        })
        
        question = f"**{template['title']}** ê´€ë ¨ ë¬¸ì˜ì‹œêµ°ìš”!\n"
        question += "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n\n"
        
        for i, opt in enumerate(template['options'], 1):
            question += f"{i}ï¸âƒ£  {opt}\n"
        
        question += f"{len(template['options'])+1}ï¸âƒ£  ê¸°íƒ€\n\n"
        question += "ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        
        return question
    
    def _is_out_of_scope(self, query: str, similarity_score: float) -> bool:
        """ë²”ìœ„ ë°– íŒë‹¨"""
        if similarity_score < 0.25:
            off_topic = [
                'ë‚ ì”¨', 'ë‰´ìŠ¤', 'ì£¼ì‹', 'ë§›ì§‘', 'ì—¬í–‰', 'ì˜í™”', 
                'ë“œë¼ë§ˆ', 'ìŒì•…', 'ê²Œì„', 'ìš”ë¦¬', 'ìš´ë™'
            ]
            return any(keyword in query for keyword in off_topic)
        return False
    
    def search_knowledge(self, 
                        query: str, 
                        category: str = None,
                        session_id: str = None) -> Dict:
        """
        ì§€ì‹ ê²€ìƒ‰ (ëŒ€í™” ë§¥ë½ ì§€ì›)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            category: ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬
            session_id: ì„¸ì…˜ ID (ëŒ€í™” ë§¥ë½ìš©)
        
        Returns:
            {
                "answer": ë‹µë³€,
                "needs_clarification": ì¬ì§ˆë¬¸ í•„ìš”,
                "clarification_question": ì¬ì§ˆë¬¸,
                "confidence": ì‹ ë¢°ë„,
                "context_used": ë§¥ë½ ì‚¬ìš© ì—¬ë¶€
            }
        """
        original_query = query
        
        # 1. ëŒ€í™” ë§¥ë½ì—ì„œ ì§€ì‹œ ëŒ€ëª…ì‚¬ í•´ê²°
        if self.enable_conversation and session_id and self.conversation:
            resolved_query = self.conversation.resolve_references(session_id, query)
            
            if resolved_query != query:
                logger.info(f"[ë§¥ë½] '{query}' â†’ '{resolved_query}'")
                query = resolved_query
        
        if self.index is None:
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "needs_clarification": False,
                "out_of_scope": False
            }
        
        try:
            # 2. FAQ ê²€ìƒ‰
            results = self._search_faq(query, category=category, top_k=3)
            
            if not results:
                return {
                    "answer": self._generate_out_of_scope_message(),
                    "needs_clarification": False,
                    "out_of_scope": True,
                    "confidence": 0.0
                }
            
            best_match = results[0]
            score = best_match['similarity_score']
            matched_category = best_match['category']
            
            # 3. ë²”ìœ„ ë°– ì²´í¬
            if self._is_out_of_scope(query, score):
                logger.info(f"ğŸš« ë²”ìœ„ ë°– (ìœ ì‚¬ë„: {score:.3f})")
                return {
                    "answer": self._generate_out_of_scope_message(),
                    "needs_clarification": False,
                    "out_of_scope": True,
                    "confidence": score
                }
            
            # 4. ì• ë§¤ëª¨í˜¸ ì²´í¬
            is_ambig, reason = self._is_ambiguous(query, score, matched_category)
            
            if is_ambig:
                logger.info(f"â“ ì• ë§¤ëª¨í˜¸ (ìœ ì‚¬ë„: {score:.3f}, ì´ìœ : {reason})")
                return {
                    "answer": None,
                    "needs_clarification": True,
                    "clarification_question": self._generate_clarification_question(
                        matched_category, results
                    ),
                    "out_of_scope": False,
                    "confidence": score
                }
            
            # 5. ë‹µë³€ ìƒì„±
            if score >= 0.70:
                logger.info(f"âœ… FAQ ë§¤ì¹­ (ìœ ì‚¬ë„: {score:.3f})")
                answer = best_match['answer']
                used_ai = False
                suggested_action = self._extract_first_action(answer)
            
            elif score >= 0.50:
                logger.info(f"âš ï¸  ì¤‘ê°„ ë§¤ì¹­ (ìœ ì‚¬ë„: {score:.3f})")
                answer = f"{best_match['answer']}\n\nğŸ’¡ ì¶”ê°€ ë¬¸ì˜: ê³ ê°ì„¼í„°(1234-5678)"
                used_ai = False
                suggested_action = self._extract_first_action(answer)
            
            else:
                # AI ì‚¬ìš© (ì„ íƒ)
                if self.use_ai_fallback and self.ai_client:
                    logger.info(f"ğŸ¤– AI í˜¸ì¶œ (ìœ ì‚¬ë„: {score:.3f})")
                    
                    if self.enable_conversation and session_id and self.conversation:
                        extended_query = self.conversation.add_context_to_prompt(session_id, query)
                    else:
                        extended_query = query
                    
                    answer = self._generate_ai_answer(extended_query, results)
                    used_ai = True
                    suggested_action = None
                else:
                    logger.info(f"âŒ ë‚®ì€ ë§¤ì¹­ (ìœ ì‚¬ë„: {score:.3f})")
                    answer = "ëª…í™•í•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³ ê°ì„¼í„°(1234-5678)ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                    used_ai = False
                    suggested_action = None
            
            # 6. ëŒ€í™” ê¸°ë¡ ì €ì¥
            if self.enable_conversation and session_id and self.conversation:
                self.conversation.add_turn(
                    session_id=session_id,
                    user_query=original_query,
                    bot_response=answer,
                    suggested_action=suggested_action,
                    faq_id=best_match.get('faq_id')
                )
            
            return {
                "answer": answer,
                "needs_clarification": False,
                "out_of_scope": False,
                "confidence": score,
                "used_ai": used_ai,
                "matched_faq_id": best_match['faq_id'],
                "context_used": original_query != query
            }
                
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {
                "answer": "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "needs_clarification": False,
                "out_of_scope": False
            }
    
    def _extract_first_action(self, answer: str) -> Optional[str]:
        """ë‹µë³€ì—ì„œ ì²« ë²ˆì§¸ ì œì•ˆ ì¡°ì¹˜ ì¶”ì¶œ"""
        match = re.search(r'1\.\s*([^\n]+)', answer)
        if match:
            action = match.group(1).strip()
            action = re.sub(r'\([^)]*\)', '', action).strip()
            return action[:50]
        return None
    
    def _search_faq(self, query: str, category: str = None, top_k: int = 3) -> List[Dict]:
        """FAQ ê²€ìƒ‰"""
        if self.index is None:
            return []
        
        try:
            query_embedding = self.model.encode([query], convert_to_numpy=True)
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.index.search(query_embedding, min(top_k * 2, len(self.faq_df)))
            
            results = []
            for score, idx in zip(scores[0], indices[0]):
                if score < 0.2:
                    continue
                
                faq_row = self.faq_df.iloc[idx]
                
                if category and faq_row['category'] != category:
                    continue
                
                results.append({
                    'faq_id': faq_row['id'],
                    'category': faq_row['category'],
                    'question': faq_row['question'],
                    'answer': faq_row['answer'],
                    'similarity_score': float(score)
                })
                
                if len(results) >= top_k:
                    break
            
            return results
            
        except Exception as e:
            logger.error(f"FAQ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _generate_ai_answer(self, query: str, faq_results: List[Dict]) -> str:
        """AI ë‹µë³€ ìƒì„±"""
        if not self.ai_client:
            return "AI ë‹µë³€ ìƒì„± ë¶ˆê°€"
        
        try:
            context = ""
            if faq_results:
                context = "ì°¸ê³  FAQ:\n"
                for faq in faq_results[:2]:
                    context += f"Q: {faq['question']}\nA: {faq['answer'][:100]}...\n\n"
            
            response = self.ai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ì¹œì ˆí•œ ê³ ê° ì§€ì› AIì…ë‹ˆë‹¤."},
                    {"role": "user", "content": f"{context}\nì§ˆë¬¸: {query}"}
                ],
                temperature=0.7,
                max_tokens=400
            )
            
            answer = response.choices[0].message.content.strip()
            answer += "\n\nğŸ¤– (AI ìƒì„± ë‹µë³€)"
            return answer
            
        except Exception as e:
            logger.error(f"AI ìƒì„± ì‹¤íŒ¨: {e}")
            return "AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_out_of_scope_message(self) -> str:
        """ë²”ìœ„ ë°– ë©”ì‹œì§€"""
        return """ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì•¼ë§Œ ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤:

âœ… **ì§€ì› ê°€ëŠ¥ ë¶„ì•¼**
â€¢ ğŸ› ï¸  ê¸°ìˆ  ì§€ì› (ì¸í„°ë„·, ì•±, ê¸°ê¸° ë¬¸ì œ)
â€¢ ğŸ’³ ì²­êµ¬ ì§€ì› (ìš”ê¸ˆ, ê²°ì œ, í™˜ë¶ˆ)
â€¢ ğŸ“¦ ì£¼ë¬¸ ê´€ë¦¬ (ì£¼ë¬¸, ë°°ì†¡, êµí™˜/ë°˜í’ˆ)
â€¢ ğŸ‘¤ ê³„ì • ê´€ë¦¬ (ë¡œê·¸ì¸, ë¹„ë°€ë²ˆí˜¸, íšŒì›ì •ë³´)

ê³ ê°ì„¼í„°: 1234-5678"""
    
    def get_conversation_summary(self, session_id: str) -> Dict:
        """ëŒ€í™” ë§¥ë½ ìš”ì•½"""
        if not self.enable_conversation or not self.conversation:
            return {'has_context': False}
        
        return self.conversation.get_context_summary(session_id)


# ==================== í…ŒìŠ¤íŠ¸ ====================

def test_integrated_service():
    """í†µí•© ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("í†µí•© ì§€ì‹ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ (All-in-One)")
    print("=" * 70)
    
    service = KnowledgeService(
        csv_path="faq_database_48.csv",
        enable_conversation=True
    )
    
    session_id = "test_session_001"
    
    # ëŒ€í™” 1
    print("\n[ëŒ€í™” 1]")
    query1 = "ì¸í„°ë„·ì´ ì•ˆ ë¼ìš”"
    result1 = service.search_knowledge(query1, "tech_support", session_id)
    
    print(f"ì‚¬ìš©ì: {query1}")
    print(f"ë´‡: {result1['answer'][:100]}...")
    
    # ëŒ€í™” 2 - ì§€ì‹œ ëŒ€ëª…ì‚¬
    print("\n" + "=" * 70)
    print("[ëŒ€í™” 2]")
    query2 = "ê·¸ê±° í–ˆëŠ”ë°ë„ ì•ˆ ë¼ìš”"
    result2 = service.search_knowledge(query2, "tech_support", session_id)
    
    print(f"ì‚¬ìš©ì: {query2}")
    print(f"ë§¥ë½ ì‚¬ìš©: {result2.get('context_used')}")
    print(f"ë´‡: {result2['answer'][:100]}...")
    
    # ëŒ€í™” 3
    print("\n" + "=" * 70)
    print("[ëŒ€í™” 3]")
    query3 = "ì´ê²ƒë„ ì•ˆ ë¼ìš”"
    result3 = service.search_knowledge(query3, "tech_support", session_id)
    
    print(f"ì‚¬ìš©ì: {query3}")
    print(f"ë§¥ë½ ì‚¬ìš©: {result3.get('context_used')}")
    
    summary = service.get_conversation_summary(session_id)
    print(f"ì‹œë„í•œ ë°©ë²•: {summary.get('tried_solutions', [])}")
    
    print("\n" + "=" * 70)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)


if __name__ == "__main__":
    test_integrated_service()